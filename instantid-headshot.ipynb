{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"93f369cf5f9944c2bee4e987614c2cd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea372c08eece4f4a99cdc5d0cb876a2e","IPY_MODEL_752b6e2b2e824376a3be10afc82b998e","IPY_MODEL_a154acc03d0c42bb90c7adcfb2ed133d"],"layout":"IPY_MODEL_1b713e061e4a4642badd8b465b936cf6"}},"ea372c08eece4f4a99cdc5d0cb876a2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6691263ea3b94aea8c699efb57234f02","placeholder":"​","style":"IPY_MODEL_baf4d9a8b7134c5181c20f6a1311e563","value":"Loading pipeline components...: 100%"}},"752b6e2b2e824376a3be10afc82b998e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1579c4985204d5c99715c7251fc7806","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4738c1ebac74b66bda04e65188d4ec0","value":7}},"a154acc03d0c42bb90c7adcfb2ed133d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c9468e2bf1d4a24bd6b38e30ae78bfb","placeholder":"​","style":"IPY_MODEL_d8cfa7ce2e2d463f96b203c56049c1fd","value":" 7/7 [00:03&lt;00:00,  2.85it/s]"}},"1b713e061e4a4642badd8b465b936cf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6691263ea3b94aea8c699efb57234f02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baf4d9a8b7134c5181c20f6a1311e563":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1579c4985204d5c99715c7251fc7806":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4738c1ebac74b66bda04e65188d4ec0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c9468e2bf1d4a24bd6b38e30ae78bfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8cfa7ce2e2d463f96b203c56049c1fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generating Headshot image using InstantID\nInstantID is a new state-of-the-art tuning-free method to achieve ID-Preserving generation with only single image, supporting various downstream tasks.\n\n[More Deails](https://github.com/InstantID/InstantID)\n","metadata":{"id":"RetoFq7-j9lD"}},{"cell_type":"markdown","source":"## 1. Clone the Repo","metadata":{"id":"2f_-XmpHkiPF"}},{"cell_type":"code","source":"!git clone https://github.com/surajkarki66/instantid-headshot.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2rURgKZkWsi","outputId":"e1e96fe5-00da-496f-aa0b-47b9476f3d92","execution":{"iopub.status.busy":"2024-06-06T07:36:01.777156Z","iopub.execute_input":"2024-06-06T07:36:01.777461Z","iopub.status.idle":"2024-06-06T07:36:03.246570Z","shell.execute_reply.started":"2024-06-06T07:36:01.777429Z","shell.execute_reply":"2024-06-06T07:36:03.245647Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'instantid-headshot'...\nremote: Enumerating objects: 43, done.\u001b[K\nremote: Counting objects: 100% (43/43), done.\u001b[K\nremote: Compressing objects: 100% (33/33), done.\u001b[K\nremote: Total 43 (delta 18), reused 32 (delta 9), pack-reused 0\u001b[K\nUnpacking objects: 100% (43/43), 49.35 KiB | 2.47 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Install Dependencies","metadata":{"id":"Krjfef5pvOSa"}},{"cell_type":"code","source":"!cd ./instantid-headshot && pip install -r \"requirements.txt\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eQPylkU1u8Fh","outputId":"f3040642-c1d8-43e5-d269-d85dbadc534a","execution":{"iopub.status.busy":"2024-06-06T07:36:03.248884Z","iopub.execute_input":"2024-06-06T07:36:03.249310Z","iopub.status.idle":"2024-06-06T07:37:16.661961Z","shell.execute_reply.started":"2024-06-06T07:36:03.249271Z","shell.execute_reply":"2024-06-06T07:37:16.660689Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown (from -r requirements.txt (line 1))\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.23.2)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.10.0.82)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.41.2)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.30.1)\nCollecting diffusers (from -r requirements.txt (line 6))\n  Downloading diffusers-0.28.2-py3-none-any.whl.metadata (19 kB)\nCollecting onnxruntime-gpu (from -r requirements.txt (line 7))\n  Downloading onnxruntime_gpu-1.18.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nCollecting insightface (from -r requirements.txt (line 8))\n  Downloading insightface-0.7.3.tar.gz (439 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting omegaconf (from -r requirements.txt (line 9))\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting controlnet_aux (from -r requirements.txt (line 10))\n  Downloading controlnet_aux-0.0.9-py3-none-any.whl.metadata (6.5 kB)\nCollecting gradio (from -r requirements.txt (line 11))\n  Downloading gradio-4.33.0-py3-none-any.whl.metadata (15 kB)\nCollecting peft (from -r requirements.txt (line 12))\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.16.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (0.4.3)\nCollecting einops (from -r requirements.txt (line 16))\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting spaces (from -r requirements.txt (line 17))\n  Downloading spaces-0.28.3-py3-none-any.whl.metadata (997 bytes)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 1)) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 1)) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 1)) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown->-r requirements.txt (line 1)) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 2)) (2024.3.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 2)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 2)) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->-r requirements.txt (line 2)) (4.9.0)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python->-r requirements.txt (line 3)) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 4)) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 4)) (0.19.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 5)) (5.9.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers->-r requirements.txt (line 6)) (6.11.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers->-r requirements.txt (line 6)) (9.5.0)\nCollecting coloredlogs (from onnxruntime-gpu->-r requirements.txt (line 7))\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu->-r requirements.txt (line 7)) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu->-r requirements.txt (line 7)) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime-gpu->-r requirements.txt (line 7)) (1.12.1)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (1.16.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (3.7.5)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (1.11.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (1.2.2)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (0.22.0)\nRequirement already satisfied: easydict in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (1.13)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (3.0.8)\nRequirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (1.4.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from insightface->-r requirements.txt (line 8)) (3.9.0)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 9))\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from controlnet_aux->-r requirements.txt (line 10)) (4.10.0.82)\nCollecting timm<=0.6.7 (from controlnet_aux->-r requirements.txt (line 10))\n  Downloading timm-0.6.7-py3-none-any.whl.metadata (33 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (5.3.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.108.0)\nCollecting ffmpy (from gradio->-r requirements.txt (line 11))\n  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==0.17.0 (from gradio->-r requirements.txt (line 11))\n  Downloading gradio_client-0.17.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.27.0)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (6.1.1)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (2.1.3)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (3.9.10)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (2.2.1)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (2.5.3)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.25.1)\nCollecting python-multipart>=0.0.9 (from gradio->-r requirements.txt (line 11))\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nCollecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 11))\n  Downloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\nCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 11))\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 11))\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting typer<1.0,>=0.12 (from gradio->-r requirements.txt (line 11))\n  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\nCollecting urllib3~=2.0 (from gradio->-r requirements.txt (line 11))\n  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r requirements.txt (line 11)) (0.25.0)\nCollecting websockets<12.0,>=10.0 (from gradio-client==0.17.0->gradio->-r requirements.txt (line 11))\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 13)) (3.2.1)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.12.1)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (0.14.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface->-r requirements.txt (line 8)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface->-r requirements.txt (line 8)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface->-r requirements.txt (line 8)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface->-r requirements.txt (line 8)) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface->-r requirements.txt (line 8)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->insightface->-r requirements.txt (line 8)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 11)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 11)) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 11)) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio->-r requirements.txt (line 11)) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->-r requirements.txt (line 1)) (3.3.2)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (13.7.0)\nRequirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from albumentations->insightface->-r requirements.txt (line 8)) (0.0.4)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface->-r requirements.txt (line 8)) (2.33.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface->-r requirements.txt (line 8)) (2023.12.9)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->insightface->-r requirements.txt (line 8)) (0.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown->-r requirements.txt (line 1)) (2.5)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 7))\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio->-r requirements.txt (line 11)) (0.32.0.post1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers->-r requirements.txt (line 6)) (3.17.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->insightface->-r requirements.txt (line 8)) (0.2.13)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown->-r requirements.txt (line 1)) (1.7.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->insightface->-r requirements.txt (line 8)) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->insightface->-r requirements.txt (line 8)) (3.2.0)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime-gpu->-r requirements.txt (line 7)) (1.3.0)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 11)) (0.16.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->insightface->-r requirements.txt (line 8)) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (2.17.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio->-r requirements.txt (line 11)) (1.2.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 11)) (0.1.2)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nDownloading diffusers-0.28.2-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading onnxruntime_gpu-1.18.0-cp310-cp310-manylinux_2_28_x86_64.whl (199.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading controlnet_aux-0.0.9-py3-none-any.whl (282 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.4/282.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gradio-4.33.0-py3-none-any.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-0.17.0-py3-none-any.whl (316 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.3/316.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading spaces-0.28.3-py3-none-any.whl (18 kB)\nDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading timm-0.6.7-py3-none-any.whl (509 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: insightface, antlr4-python3-runtime, ffmpy\n  Building wheel for insightface (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for insightface: filename=insightface-0.7.3-cp310-cp310-linux_x86_64.whl size=882816 sha256=f75a14b424875d4e81ee74c6c45eae2ca77944e13fd60d73d0914c417cefc572\n  Stored in directory: /root/.cache/pip/wheels/e3/d0/80/e3773fb8b6d1cca87ea1d33d9b1f20a223a6493c896da249b5\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=9a167429cec27f13fb50828d46a64aceddb6281bafbb082c01ba1fbcee57d843\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=aa282cf253932a1854a3f222da6fa7544ec3ec67465cf152e2b25e2b66c52278\n  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\nSuccessfully built insightface antlr4-python3-runtime ffmpy\nInstalling collected packages: ffmpy, antlr4-python3-runtime, websockets, urllib3, tomlkit, semantic-version, ruff, python-multipart, omegaconf, humanfriendly, einops, coloredlogs, typer, onnxruntime-gpu, timm, gradio-client, gdown, diffusers, insightface, gradio, controlnet_aux, spaces, peft\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.12.5\n    Uninstalling tomlkit-0.12.5:\n      Successfully uninstalled tomlkit-0.12.5\n  Attempting uninstall: typer\n    Found existing installation: typer 0.9.0\n    Uninstalling typer-0.9.0:\n      Successfully uninstalled typer-0.9.0\n  Attempting uninstall: timm\n    Found existing installation: timm 1.0.3\n    Uninstalling timm-1.0.3:\n      Successfully uninstalled timm-1.0.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nweasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 controlnet_aux-0.0.9 diffusers-0.28.2 einops-0.8.0 ffmpy-0.3.2 gdown-5.2.0 gradio-4.33.0 gradio-client-0.17.0 humanfriendly-10.0 insightface-0.7.3 omegaconf-2.3.0 onnxruntime-gpu-1.18.0 peft-0.11.1 python-multipart-0.0.9 ruff-0.4.8 semantic-version-2.10.0 spaces-0.28.3 timm-0.6.7 tomlkit-0.12.0 typer-0.12.3 urllib3-2.1.0 websockets-11.0.3\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 3. Download Models","metadata":{"id":"yx5gKxO6wQuF"}},{"cell_type":"code","source":"!cd ./instantid-headshot && python download_models.py","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zg6v85K_vVDQ","outputId":"87f7d1a2-0a73-4a8e-cf5b-3bbd6fbf21fb","execution":{"iopub.status.busy":"2024-06-06T07:37:16.664353Z","iopub.execute_input":"2024-06-06T07:37:16.664702Z","iopub.status.idle":"2024-06-06T07:37:40.113937Z","shell.execute_reply.started":"2024-06-06T07:37:16.664671Z","shell.execute_reply":"2024-06-06T07:37:40.112808Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"ControlNetModel/config.json: 100%|█████████| 1.38k/1.38k [00:00<00:00, 7.02MB/s]\ndiffusion_pytorch_model.safetensors: 100%|██| 2.50G/2.50G [00:07<00:00, 315MB/s]\nip-adapter.bin: 100%|███████████████████████| 1.69G/1.69G [00:05<00:00, 301MB/s]\npytorch_lora_weights.safetensors: 100%|███████| 394M/394M [00:01<00:00, 307MB/s]\nDownloading...\nFrom (original): https://drive.google.com/uc?id=18wEUfMNohBJ4K3Ly5wpTejPfDzp-8fI8\nFrom (redirected): https://drive.google.com/uc?id=18wEUfMNohBJ4K3Ly5wpTejPfDzp-8fI8&confirm=t&uuid=a6f1f0e5-83a4-45b9-a2cd-5cb615d16bac\nTo: /kaggle/working/instantid-headshot/models/antelopev2.zip\n100%|█████████████████████████████████████████| 361M/361M [00:01<00:00, 216MB/s]\nArchive:  ./models/antelopev2.zip\n   creating: ./models/antelopev2/\n  inflating: ./models/antelopev2/genderage.onnx  \n  inflating: ./models/antelopev2/2d106det.onnx  \n  inflating: ./models/antelopev2/1k3d68.onnx  \n  inflating: ./models/antelopev2/glintr100.onnx  \n  inflating: ./models/antelopev2/scrfd_10g_bnkps.onnx  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4. Imports","metadata":{"id":"81Wrp7NmYN4B"}},{"cell_type":"code","source":"%cd ./instantid-headshot\nimport sys\nsys.path.append('./')\n\nfrom typing import Tuple\n\nimport os\nimport cv2\nimport math\nimport torch\nimport random\nimport numpy as np\nimport argparse\n\nimport PIL\nfrom PIL import Image\n\nimport diffusers\nfrom diffusers.utils import load_image\nfrom diffusers.models import ControlNetModel\nfrom diffusers import LCMScheduler\n\nfrom huggingface_hub import hf_hub_download\n\nimport insightface\nfrom insightface.app import FaceAnalysis\n\nfrom style_template import styles\nfrom pipeline_stable_diffusion_xl_instantid_full import StableDiffusionXLInstantIDPipeline\nfrom model_util import load_models_xl, get_torch_device, torch_gc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DraNS6pzYGrI","outputId":"b21bed95-593c-4287-d18f-da7f15e201b7","execution":{"iopub.status.busy":"2024-06-06T07:37:40.116004Z","iopub.execute_input":"2024-06-06T07:37:40.116338Z","iopub.status.idle":"2024-06-06T07:38:00.899180Z","shell.execute_reply.started":"2024-06-06T07:37:40.116309Z","shell.execute_reply":"2024-06-06T07:38:00.898343Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/working/instantid-headshot\n","output_type":"stream"},{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3afe7cdfe5b42f5ad6c6312b6ec72c9"}},"metadata":{}},{"name":"stderr","text":"2024-06-06 07:37:49.270470: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-06 07:37:49.270572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-06 07:37:49.386202: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 4. Run","metadata":{"id":"rKzy5X9_w8Tv"}},{"cell_type":"code","source":"def randomize_seed_fn(seed: int, randomize_seed: bool) -> int:\n    if randomize_seed:\n        seed = random.randint(0, MAX_SEED)\n    return seed","metadata":{"id":"kEO2wn97WhSR","execution":{"iopub.status.busy":"2024-06-06T07:38:00.901676Z","iopub.execute_input":"2024-06-06T07:38:00.902415Z","iopub.status.idle":"2024-06-06T07:38:00.907463Z","shell.execute_reply.started":"2024-06-06T07:38:00.902376Z","shell.execute_reply":"2024-06-06T07:38:00.906496Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def convert_from_cv2_to_image(img: np.ndarray) -> Image:\n    return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))","metadata":{"id":"tapB5bLOWifp","execution":{"iopub.status.busy":"2024-06-06T07:38:00.908727Z","iopub.execute_input":"2024-06-06T07:38:00.909123Z","iopub.status.idle":"2024-06-06T07:38:01.797532Z","shell.execute_reply.started":"2024-06-06T07:38:00.909086Z","shell.execute_reply":"2024-06-06T07:38:01.796483Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def convert_from_image_to_cv2(img: Image) -> np.ndarray:\n    return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)","metadata":{"id":"tpv4N9yWWipz","execution":{"iopub.status.busy":"2024-06-06T07:38:01.798794Z","iopub.execute_input":"2024-06-06T07:38:01.799142Z","iopub.status.idle":"2024-06-06T07:38:01.809119Z","shell.execute_reply.started":"2024-06-06T07:38:01.799108Z","shell.execute_reply":"2024-06-06T07:38:01.808203Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def draw_kps(image_pil, kps, color_list=[(255,0,0), (0,255,0), (0,0,255), (255,255,0), (255,0,255)]):\n    stickwidth = 4\n    limbSeq = np.array([[0, 2], [1, 2], [3, 2], [4, 2]])\n    kps = np.array(kps)\n\n    w, h = image_pil.size\n    out_img = np.zeros([h, w, 3])\n\n    for i in range(len(limbSeq)):\n        index = limbSeq[i]\n        color = color_list[index[0]]\n\n        x = kps[index][:, 0]\n        y = kps[index][:, 1]\n        length = ((x[0] - x[1]) ** 2 + (y[0] - y[1]) ** 2) ** 0.5\n        angle = math.degrees(math.atan2(y[0] - y[1], x[0] - x[1]))\n        polygon = cv2.ellipse2Poly((int(np.mean(x)), int(np.mean(y))), (int(length / 2), stickwidth), int(angle), 0, 360, 1)\n        out_img = cv2.fillConvexPoly(out_img.copy(), polygon, color)\n    out_img = (out_img * 0.6).astype(np.uint8)\n\n    for idx_kp, kp in enumerate(kps):\n        color = color_list[idx_kp]\n        x, y = kp\n        out_img = cv2.circle(out_img.copy(), (int(x), int(y)), 10, color, -1)\n\n    out_img_pil = Image.fromarray(out_img.astype(np.uint8))\n    return out_img_pil","metadata":{"id":"lFrIR2KnWizW","execution":{"iopub.status.busy":"2024-06-06T07:38:01.810296Z","iopub.execute_input":"2024-06-06T07:38:01.810838Z","iopub.status.idle":"2024-06-06T07:38:01.823072Z","shell.execute_reply.started":"2024-06-06T07:38:01.810812Z","shell.execute_reply":"2024-06-06T07:38:01.822282Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def resize_img(input_image, max_side=1280, min_side=1024, size=None,\n      pad_to_max_side=False, mode=PIL.Image.BILINEAR, base_pixel_number=64):\n\n    w, h = input_image.size\n    if size is not None:\n        w_resize_new, h_resize_new = size\n    else:\n        ratio = min_side / min(h, w)\n        w, h = round(ratio*w), round(ratio*h)\n        ratio = max_side / max(h, w)\n        input_image = input_image.resize([round(ratio*w), round(ratio*h)], mode)\n        w_resize_new = (round(ratio * w) // base_pixel_number) * base_pixel_number\n        h_resize_new = (round(ratio * h) // base_pixel_number) * base_pixel_number\n    input_image = input_image.resize([w_resize_new, h_resize_new], mode)\n\n    if pad_to_max_side:\n        res = np.ones([max_side, max_side, 3], dtype=np.uint8) * 255\n        offset_x = (max_side - w_resize_new) // 2\n        offset_y = (max_side - h_resize_new) // 2\n        res[offset_y:offset_y+h_resize_new, offset_x:offset_x+w_resize_new] = np.array(input_image)\n        input_image = Image.fromarray(res)\n    return input_image","metadata":{"id":"iozY_EHqW2KM","execution":{"iopub.status.busy":"2024-06-06T07:38:01.824107Z","iopub.execute_input":"2024-06-06T07:38:01.824365Z","iopub.status.idle":"2024-06-06T07:38:01.837786Z","shell.execute_reply.started":"2024-06-06T07:38:01.824343Z","shell.execute_reply":"2024-06-06T07:38:01.837018Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def apply_style(style_name: str, positive: str, negative: str = \"\") -> Tuple[str, str]:\n    p, n = styles.get(style_name, styles[DEFAULT_STYLE_NAME])\n    return p.replace(\"{prompt}\", positive), n + ' ' + negative","metadata":{"id":"leDr8l20W2WJ","execution":{"iopub.status.busy":"2024-06-06T07:38:01.838725Z","iopub.execute_input":"2024-06-06T07:38:01.838980Z","iopub.status.idle":"2024-06-06T07:38:01.851953Z","shell.execute_reply.started":"2024-06-06T07:38:01.838958Z","shell.execute_reply":"2024-06-06T07:38:01.851280Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def generate_image(pipe, face_image_path, pose_image_path, prompt, negative_prompt, style_name, num_steps, identitynet_strength_ratio, adapter_strength_ratio, guidance_scale, seed, enable_LCM, enhance_face_region):\n  if enable_LCM:\n      pipe.enable_lora()\n      pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n  else:\n      pipe.disable_lora()\n      pipe.scheduler = diffusers.EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n\n\n  if prompt is None:\n      prompt = \"a person\"\n\n  # apply the style template\n  prompt, negative_prompt = apply_style(style_name, prompt, negative_prompt)\n\n  face_image = load_image(face_image_path)\n  face_image = resize_img(face_image)\n  face_image_cv2 = convert_from_image_to_cv2(face_image)\n  height, width, _ = face_image_cv2.shape\n\n  # Extract face features\n  face_info = app.get(face_image_cv2)\n\n  if len(face_info) == 0:\n      raise Exception(f\"Cannot find any face in the image! Please upload another person image\")\n\n  face_info = sorted(face_info, key=lambda x:(x['bbox'][2]-x['bbox'][0])*(x['bbox'][3]-x['bbox'][1]))[-1]  # only use the maximum face\n  face_emb = face_info['embedding']\n  face_kps = draw_kps(convert_from_cv2_to_image(face_image_cv2), face_info['kps'])\n\n  if pose_image_path is not None:\n      pose_image = load_image(pose_image_path)\n      pose_image = resize_img(pose_image)\n      pose_image_cv2 = convert_from_image_to_cv2(pose_image)\n\n      face_info = app.get(pose_image_cv2)\n\n      if len(face_info) == 0:\n          raise Exception(f\"Cannot find any face in the reference image! Please upload another person image\")\n\n      face_info = face_info[-1]\n      face_kps = draw_kps(pose_image, face_info['kps'])\n\n      width, height = face_kps.size\n\n  if enhance_face_region:\n      control_mask = np.zeros([height, width, 3])\n      x1, y1, x2, y2 = face_info[\"bbox\"]\n      x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n      control_mask[y1:y2, x1:x2] = 255\n      control_mask = Image.fromarray(control_mask.astype(np.uint8))\n  else:\n      control_mask = None\n\n  generator = torch.Generator(device=device).manual_seed(seed)\n\n  print(\"Start inference...\")\n  print(f\"[Debug] Prompt: {prompt}, \\n[Debug] Neg Prompt: {negative_prompt}\")\n\n  pipe.set_ip_adapter_scale(adapter_strength_ratio)\n  images = pipe(\n      prompt=prompt,\n      negative_prompt=negative_prompt,\n      image_embeds=face_emb,\n      image=face_kps,\n      control_mask=control_mask,\n      controlnet_conditioning_scale=float(identitynet_strength_ratio),\n      num_inference_steps=num_steps,\n      guidance_scale=guidance_scale,\n      height=height,\n      width=width,\n      generator=generator\n  ).images\n\n  return images[0]","metadata":{"id":"SNbswqKEXnsP","execution":{"iopub.status.busy":"2024-06-06T07:38:01.854448Z","iopub.execute_input":"2024-06-06T07:38:01.854707Z","iopub.status.idle":"2024-06-06T07:38:01.869168Z","shell.execute_reply.started":"2024-06-06T07:38:01.854685Z","shell.execute_reply":"2024-06-06T07:38:01.868291Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# global variable\nMAX_SEED = np.iinfo(np.int32).max\ndevice = get_torch_device()\ndtype = torch.float16 if str(device).__contains__(\"cuda\") else torch.float32\nSTYLE_NAMES = list(styles.keys())\nDEFAULT_STYLE_NAME = \"(No style)\"\n\n# Load face encoder\napp = FaceAnalysis(name='antelopev2', root='./', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\napp.prepare(ctx_id=0, det_size=(640, 640))\n\n# Path to InstantID models\nface_adapter = f'./checkpoints/ip-adapter.bin'\ncontrolnet_path = f'./checkpoints/ControlNetModel'\n\n# Load pipeline\ncontrolnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=dtype)\n\npretrained_model_name_or_path=\"wangqixun/YamerMIX_v8\"\n\nif pretrained_model_name_or_path.endswith(\n        \".ckpt\"\n    ) or pretrained_model_name_or_path.endswith(\".safetensors\"):\n        scheduler_kwargs = hf_hub_download(\n            repo_id=\"wangqixun/YamerMIX_v8\",\n            subfolder=\"scheduler\",\n            filename=\"scheduler_config.json\",\n        )\n\n        (tokenizers, text_encoders, unet, _, vae) = load_models_xl(\n            pretrained_model_name_or_path=pretrained_model_name_or_path,\n            scheduler_name=None,\n            weight_dtype=dtype,\n        )\n\n        scheduler = diffusers.EulerDiscreteScheduler.from_config(scheduler_kwargs)\n        pipe = StableDiffusionXLInstantIDPipeline(\n            vae=vae,\n            text_encoder=text_encoders[0],\n            text_encoder_2=text_encoders[1],\n            tokenizer=tokenizers[0],\n            tokenizer_2=tokenizers[1],\n            unet=unet,\n            scheduler=scheduler,\n            controlnet=controlnet,\n        ).to(device)\n\nelse:\n    pipe = StableDiffusionXLInstantIDPipeline.from_pretrained(\n        pretrained_model_name_or_path,\n        controlnet=controlnet,\n        torch_dtype=dtype,\n        safety_checker=None,\n        feature_extractor=None,\n    ).to(device)\n\n    pipe.scheduler = diffusers.EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n\n\npipe.load_ip_adapter_instantid(face_adapter)\n\n# load and disable LCM\npipe.load_lora_weights(\"latent-consistency/lcm-lora-sdxl\")\npipe.disable_lora()\n\ninput_img = \"./WhatsApp Image 2024-06-05 at 12.56.09.jpeg\"\nreference_img = \"./WhatsApp Image 2024-06-05 at 12.57.39.jpeg\"\n\nout_img = generate_image(pipe, face_image_path=input_img, pose_image_path=reference_img, prompt=\"professional headshot, linkedin profile picture, realistic photo\", negative_prompt=\"bad quality, unrealistic\", style_name=None, num_steps=30, identitynet_strength_ratio=0.8, adapter_strength_ratio=0.8, guidance_scale=5, seed=810087237, enable_LCM=True, enhance_face_region=True)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":731,"referenced_widgets":["93f369cf5f9944c2bee4e987614c2cd6","ea372c08eece4f4a99cdc5d0cb876a2e","752b6e2b2e824376a3be10afc82b998e","a154acc03d0c42bb90c7adcfb2ed133d","1b713e061e4a4642badd8b465b936cf6","6691263ea3b94aea8c699efb57234f02","baf4d9a8b7134c5181c20f6a1311e563","c1579c4985204d5c99715c7251fc7806","d4738c1ebac74b66bda04e65188d4ec0","2c9468e2bf1d4a24bd6b38e30ae78bfb","d8cfa7ce2e2d463f96b203c56049c1fd"]},"id":"4BEMlcOhwasL","outputId":"ab29fffc-aff3-4bef-f344-ef7baded9a83","execution":{"iopub.status.busy":"2024-06-06T07:46:04.560836Z","iopub.execute_input":"2024-06-06T07:46:04.561639Z","iopub.status.idle":"2024-06-06T07:46:08.785755Z","shell.execute_reply.started":"2024-06-06T07:46:04.561603Z","shell.execute_reply":"2024-06-06T07:46:08.784456Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: ./models/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: ./models/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: ./models/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;31m2024-06-06 07:46:04.689382793 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n\u001b[m\n\u001b[1;31m2024-06-06 07:46:05.131404747 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n\u001b[m\n\u001b[1;31m2024-06-06 07:46:05.155951343 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n\u001b[m\n\u001b[1;31m2024-06-06 07:46:05.290608199 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n\u001b[m\n","output_type":"stream"},{"name":"stdout","text":"Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: ./models/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\nApplied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\nfind model: ./models/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\nset det-size: (640, 640)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[1;31m2024-06-06 07:46:05.966692819 [E:onnxruntime:Default, provider_bridge_ort.cc:1744 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1426 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.11: cannot open shared object file: No such file or directory\n\u001b[m\nThe config attributes {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False} were passed to StableDiffusionXLInstantIDPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\nKeyword arguments {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False, 'safety_checker': None} are not expected by StableDiffusionXLInstantIDPipeline and will be ignored.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec11e1cbda874dc487cb9cd951563a45"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 55\u001b[0m\n\u001b[1;32m     37\u001b[0m         pipe \u001b[38;5;241m=\u001b[39m StableDiffusionXLInstantIDPipeline(\n\u001b[1;32m     38\u001b[0m             vae\u001b[38;5;241m=\u001b[39mvae,\n\u001b[1;32m     39\u001b[0m             text_encoder\u001b[38;5;241m=\u001b[39mtext_encoders[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m             controlnet\u001b[38;5;241m=\u001b[39mcontrolnet,\n\u001b[1;32m     46\u001b[0m         )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     pipe \u001b[38;5;241m=\u001b[39m \u001b[43mStableDiffusionXLInstantIDPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontrolnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrolnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafety_checker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m---> 55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     pipe\u001b[38;5;241m.\u001b[39mscheduler \u001b[38;5;241m=\u001b[39m diffusers\u001b[38;5;241m.\u001b[39mEulerDiscreteScheduler\u001b[38;5;241m.\u001b[39mfrom_config(pipe\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m     60\u001b[0m pipe\u001b[38;5;241m.\u001b[39mload_ip_adapter_instantid(face_adapter)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/diffusers/pipelines/pipeline_utils.py:431\u001b[0m, in \u001b[0;36mDiffusionPipeline.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been loaded in 8bit and moving it to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m via `.to()` is not yet supported. Module is still on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    434\u001b[0m     module\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(device) \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silence_dtype_warnings\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_offloaded\n\u001b[1;32m    438\u001b[0m ):\n\u001b[1;32m    439\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not recommended to move them to `cpu` as running them will fail. Please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `torch_dtype=torch.float16` argument, or use another device for inference.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 30.12 MiB is free. Process 2538 has 15.86 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 312.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 30.12 MiB is free. Process 2538 has 15.86 GiB memory in use. Of the allocated memory 15.31 GiB is allocated by PyTorch, and 312.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"markdown","source":"Note: To run `app-multicontrolnet.py` free collab is not sufficient.","metadata":{"id":"CT9KZbEs6SN_"}}]}